{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<boto3.dynamodb.conditions.Or at 0x7fb8f6a96080>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boto3.dynamodb.conditions import Attr\n",
    "res = (Attr('test').eq(1) & Attr('a').lt(2)) | Attr('b').contains('a')()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 2}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'a': 1}\n",
    "{**test, 'b': 2, 'a':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"( ( A__eq:int:1)AND(B__lt:date:2))OR(C__gte:str:3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " '(',\n",
       " 'A__eq',\n",
       " 'int',\n",
       " '1',\n",
       " ')',\n",
       " 'AND',\n",
       " '(',\n",
       " 'B__lt',\n",
       " 'date',\n",
       " '2',\n",
       " ')',\n",
       " ')',\n",
       " 'OR',\n",
       " '(',\n",
       " 'C__gte',\n",
       " 'str',\n",
       " '3',\n",
       " ')']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1\n",
    "# Split string into a list of untyped tokens\n",
    "import re\n",
    "separators = ['\\(', '\\)', ':']\n",
    "\n",
    "# re.partition(re.split(''))\n",
    "rstr = \"({})\".format('|'.join(separators))\n",
    "splitted = re.split(re.compile(rstr), test)\n",
    "tokens_to_ignore = {':', ''}\n",
    "no_type_tokens = list(filter(lambda tok: tok not in tokens_to_ignore, [s.strip() for s in splitted]))\n",
    "no_type_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token primary and secondary types\n",
    "\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, literal, primary_type, secondary_type):\n",
    "        if primary_type not in registered_token_types or secondary_type not in registered_token_types[primary_type]:\n",
    "            raise Exception('Attempted to tokenize an unregistered primary/secondary type')\n",
    "        \n",
    "        self.literal = literal\n",
    "        self.primary_type = primary_type\n",
    "        self.secondary_type = secondary_type\n",
    "        self.string_notation = f'{primary_type}:{secondary_type}'\n",
    "    \n",
    "    def set_string_notation(self):\n",
    "        self.string_notation = f'{primary_type}:{secondary_type}'\n",
    "    \n",
    "    def update_secondary_type(self, new_secondary_type):\n",
    "        self.secondary_type = new_secondary_type\n",
    "        self.set_string_notation()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.string_notation\n",
    "\n",
    "\n",
    "class ContextToken(Token):\n",
    "    pass\n",
    "\n",
    "\n",
    "import operator\n",
    "token_operator = {'and': operator.and_, 'or': operator.or_}\n",
    "token_precedence = {'and': 2, 'or': 1}\n",
    "\n",
    "class LogicalToken(Token):\n",
    "    def __init__(self, literal, primary_type, secondary_type):\n",
    "        super().__init__(literal, primary_type, secondary_type)\n",
    "        self.precedence = token_precedence[self.secondary_type]\n",
    "        self.operator = token_operator[self.secondary_type]\n",
    "\n",
    "from decimal import Decimal\n",
    "from datetime import datetime, date\n",
    "value_types = {\n",
    "    'int': int,\n",
    "    'str': str,\n",
    "    'float': float,\n",
    "    'decimal': Decimal,\n",
    "    'date': date,\n",
    "    'datetime': datetime\n",
    "}\n",
    "    \n",
    "class ExpressionToken(Token):\n",
    "    def get_field_and_lookup_expression(self):\n",
    "        if not self.secondary_type == 'field':\n",
    "            return None\n",
    "        \n",
    "        splitted_field = self.literal.split('__')\n",
    "        splitted_count = len(splitted_field)\n",
    "        if splitted_count == 1:\n",
    "            lookup_expression = 'eq'\n",
    "        elif splitted_count in [2, 3]:\n",
    "            lookup_expression = splitted_field[-1]\n",
    "        else:\n",
    "            raise Exception('Invalid lookup expression!')\n",
    "        \n",
    "        return splitted_field[0], lookup_expression\n",
    "    \n",
    "    def get_value_type_casting_method(self):\n",
    "        if not self.secondary_type == 'value_type':\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return value_types[self.literal]\n",
    "        except KeyError:\n",
    "            raise Exception('Invalid value type!')\n",
    "        \n",
    "\n",
    "\n",
    "registered_token_types = {\n",
    "    'context': {'open', 'close'},\n",
    "    'logical': {'and', 'or'},\n",
    "    'expression': {'field', 'value_type', 'value'}\n",
    "}\n",
    "\n",
    "general_token_types = {\n",
    "    '(': ('context', 'open'),\n",
    "    ')': ('context', 'close'),\n",
    "    'AND': ('logical', 'and'),\n",
    "    'OR': ('logical', 'or')\n",
    "}\n",
    "\n",
    "field_lambda = lambda _: ('expression', 'field')\n",
    "expression_token_types = {\n",
    "    # previous token: (typ, subtype)\n",
    "    None: field_lambda,\n",
    "    'context:open': field_lambda,\n",
    "    'expression:field': lambda next_literal: ('expression', 'value') if next_literal in [None, ')'] else ('expression', 'value_type'),\n",
    "    'expression:value_type': lambda _: ('expression', 'value')\n",
    "}\n",
    "\n",
    "primary_type_to_Token = {\n",
    "    'context': ContextToken,\n",
    "    'logical': LogicalToken,\n",
    "    'expression': ExpressionToken\n",
    "}\n",
    "\n",
    "def get_instanced_token(current_literal: str, previous_token_string_notation: str, next_literal: str):\n",
    "    try:\n",
    "        primary_type, secondary_type = general_token_types[current_literal]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            primary_type, secondary_type = expression_token_types[previous_token_string_notation](next_literal)\n",
    "        except KeyError:\n",
    "            raise Exception(f'Couldn\\'t determine token type!\\nCurrent -> {current_literal}\\nPrevious -> {previous_token_string_notation}\\nNext -> {next_literal}')\n",
    "    \n",
    "    if primary_type == None or secondary_type == None:\n",
    "        return None\n",
    "    \n",
    "    return primary_type_to_Token[primary_type](current_literal, primary_type, secondary_type)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( ( A__eq:int:1)AND(B__lt:date:2))OR(C__gte:str:3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['context:open -> (',\n",
       " 'context:open -> (',\n",
       " 'expression:field -> A__eq',\n",
       " 'expression:value_type -> int',\n",
       " 'expression:value -> 1',\n",
       " 'context:close -> )',\n",
       " 'logical:and -> AND',\n",
       " 'context:open -> (',\n",
       " 'expression:field -> B__lt',\n",
       " 'expression:value_type -> date',\n",
       " 'expression:value -> 2',\n",
       " 'context:close -> )',\n",
       " 'context:close -> )',\n",
       " 'logical:or -> OR',\n",
       " 'context:open -> (',\n",
       " 'expression:field -> C__gte',\n",
       " 'expression:value_type -> str',\n",
       " 'expression:value -> 3',\n",
       " 'context:close -> )']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instanced_tokens = []\n",
    "\n",
    "previous_token = None\n",
    "for index, current_token in enumerate(no_type_tokens):\n",
    "\n",
    "    try:\n",
    "        next_token = no_type_tokens[index + 1]\n",
    "    except IndexError:\n",
    "        next_token = None\n",
    "\n",
    "    instanced_token = get_instanced_token(current_token, previous_token, next_token)\n",
    "    instanced_tokens.append(instanced_token)\n",
    "    previous_token = str(instanced_token)\n",
    "\n",
    "print(test)\n",
    "[f'{str(t)} -> {t.literal}' for t in instanced_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left_child=None, right_child=None):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "\n",
    "class ExpressionNode(Node):\n",
    "    def __init__(self, *args):\n",
    "        \n",
    "        if len(args) not in [2, 3]:\n",
    "            raise Exception(f'Couldn\\'t build ExpressionNode! Tokens -> {args}')\n",
    "        \n",
    "        field_token = args[0]\n",
    "        value_token = args[-1]\n",
    "        value_type_token = args[1] if len(args) == 3 else None\n",
    "            \n",
    "        if any(not isinstance(tok, ExpressionToken) for tok in [field_token, value_token]):\n",
    "            raise Exception('Cannot build expression node out of non ExpressionTokens!')\n",
    "        \n",
    "        field, lookup_expression = field_token.get_lookup_expression()\n",
    "        self.field = field\n",
    "        self.lookup_expression = lookup_expression\n",
    "        \n",
    "        value_type = None if not value_type_token else value_type_token.get_value_type_casting_method()\n",
    "        self.value = value_type(value_token.literal) if value_type else value_token.literal\n",
    "        \n",
    "class LogicalNode(Node):\n",
    "    def __init__(self, logical_token, left_child, right_child):\n",
    "        self.operator = logical_token.operator\n",
    "        super().__init__(left_child, right_child)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "op_and_ expected 2 arguments, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-32b24f8a960d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mand_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: op_and_ expected 2 arguments, got 3"
     ]
    }
   ],
   "source": [
    "\n",
    "next_expected_tokens = {\n",
    "    None: {'context:open', 'expression:field'},\n",
    "    'context:open': {'context:open', 'expression:field'},\n",
    "    'context:close': {'context:close', 'logical:and', 'logical:or'},\n",
    "    'logical:and': {'context:open'},\n",
    "    'logical:or': {'context:open'},\n",
    "    'expression:field': {'expression:value_type', 'expression:value'},\n",
    "    'expression:value_type': {'expression:value'},\n",
    "    'expression:value': {'context:close'}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# build AST\n",
    "from collections import deque\n",
    "from deepcopy import deepcopy\n",
    "\n",
    "contexts_stack = []\n",
    "current_context_head = None\n",
    "current_expression_tokens = []\n",
    "parent_node = None\n",
    "expected_tokens = next_expected_tokens[None]\n",
    "\n",
    "instanced_tokens.append(None)  # End\n",
    "for tok in instanced_tokens:\n",
    "    tok_repr = str(tok)\n",
    "    if tok_repr not in expected_tokens:\n",
    "        raise Exception(f'Unexpected token encountered -> {tok_repr}, one of the following was expected -> {expected_tokens}')\n",
    "    \n",
    "    if isinstance(tok, ContextToken) and tok.secondary_type == 'open':\n",
    "        if tok.secondary_type == 'open':\n",
    "            contexts_stack.append(None)\n",
    "        elif tok.secondary_type == 'close':\n",
    "            if not contexts_stack:\n",
    "                raise Exception('Attempted to close unexistent context!')\n",
    "\n",
    "            if current_expression_tokens:\n",
    "                try:\n",
    "                    expression_node = ExpressionNode(*current_expression_tokens)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f'Couldn\\'t parse expression node! -> {e}')\n",
    "                current_expression_tokens = []\n",
    "\n",
    "                if contexts_stack[-1] == None:\n",
    "                    current_context_head = deepcopy(expression_node)\n",
    "                elif isinstance(contexts_stack[-1], LogicalNode):\n",
    "                    current_context_head.right_child = deepcopy(expression_node)\n",
    "                else:\n",
    "                    raise Exception('Found an unexpected expression??')\n",
    "                expression_node = None\n",
    "            else:\n",
    "                \n",
    "\n",
    "    elif isinstance(tok, ExpressionToken):\n",
    "        current_expression_tokens.append(tok)            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    expected_tokens = next_expected_tokens[str(tok)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
